"""
è¯­éŸ³è¯†åˆ« (ASR) æ¨¡å—

åŸºäº faster-whisper å®ç°æœ¬åœ°è¯­éŸ³è¯†åˆ«ã€‚
æ”¯æŒéº¦å…‹é£å®æ—¶å½•éŸ³ + VAD è‡ªåŠ¨æ£€æµ‹è¯­éŸ³æ®µã€‚

ä½¿ç”¨:
    asr = ASREngine()
    text = asr.listen()  # é˜»å¡ç›´åˆ°è¯´å®Œä¸€å¥è¯
"""

from __future__ import annotations

import io
import queue
import threading
import time
from typing import Optional

import numpy as np

from orb.system.services.logger import get_logger

logger = get_logger(__name__)

# å½•éŸ³å‚æ•°
SAMPLE_RATE = 16000
CHANNELS = 1
DTYPE = "float32"

# VAD å‚æ•°
SILENCE_THRESHOLD = 0.01       # é™éŸ³é˜ˆå€¼ (RMS)
SPEECH_START_FRAMES = 3        # è¿ç»­å‡ å¸§è¶…è¿‡é˜ˆå€¼æ‰ç®—å¼€å§‹è¯´è¯
SILENCE_END_SECONDS = 1.5      # è¯´è¯åé™éŸ³å¤šä¹…ç®—è¯´å®Œ
FRAME_DURATION_MS = 100        # æ¯å¸§æ—¶é•¿ (ms)
MAX_RECORD_SECONDS = 30        # æœ€é•¿å½•éŸ³æ—¶é—´


class ASREngine:
    """
    æœ¬åœ°è¯­éŸ³è¯†åˆ«å¼•æ“

    åŸºäº faster-whisper + sounddevice å®ç°ã€‚
    è°ƒç”¨ listen() ä¼šé˜»å¡ç›´åˆ°ç”¨æˆ·è¯´å®Œä¸€å¥è¯å¹¶è¿”å›æ–‡å­—ã€‚
    """

    def __init__(
        self,
        model_size: str = "small",
        language: str = "zh",
        device: str = "cpu",
        compute_type: str = "int8",
    ):
        """
        åˆå§‹åŒ– ASR å¼•æ“

        Args:
            model_size: Whisper æ¨¡å‹å¤§å° (tiny/base/small/medium/large-v3)
            language: è¯†åˆ«è¯­è¨€
            device: è¿è¡Œè®¾å¤‡ (cpu/cuda)
            compute_type: è®¡ç®—ç²¾åº¦ (int8/float16/float32)
        """
        self._model_size = model_size
        self._language = language
        self._device = device
        self._compute_type = compute_type
        self._model = None
        self._loaded = False

    def _ensure_model(self) -> None:
        """å»¶è¿ŸåŠ è½½æ¨¡å‹"""
        if self._loaded:
            return

        from faster_whisper import WhisperModel

        logger.info(f"åŠ è½½ Whisper æ¨¡å‹: {self._model_size} (é¦–æ¬¡åŠ è½½éœ€ä¸‹è½½...)")
        self._model = WhisperModel(
            self._model_size,
            device=self._device,
            compute_type=self._compute_type,
        )
        self._loaded = True
        logger.info("Whisper æ¨¡å‹åŠ è½½å®Œæˆ")

    def transcribe(self, audio_data: np.ndarray) -> str:
        """
        è¯†åˆ«éŸ³é¢‘æ•°æ®

        Args:
            audio_data: float32 numpy æ•°ç»„, é‡‡æ ·ç‡ 16kHz

        Returns:
            è¯†åˆ«å‡ºçš„æ–‡å­—
        """
        self._ensure_model()

        segments, info = self._model.transcribe(
            audio_data,
            language=self._language,
            beam_size=5,
            vad_filter=True,
        )

        text = "".join(seg.text for seg in segments).strip()
        return text

    def listen(self, prompt: str = "ğŸ¤ è¯·è¯´è¯...") -> Optional[str]:
        """
        ç›‘å¬éº¦å…‹é£å¹¶è¯†åˆ«è¯­éŸ³

        ä½¿ç”¨ VAD æ£€æµ‹è¯­éŸ³æ®µ: ç­‰å¾…è¯´è¯å¼€å§‹ â†’ å½•éŸ³ â†’ æ£€æµ‹åˆ°æ²‰é»˜ â†’ åœæ­¢ â†’ è¯†åˆ«

        Args:
            prompt: æç¤ºæ–‡å­—

        Returns:
            è¯†åˆ«å‡ºçš„æ–‡å­—ï¼Œå¦‚æœæ²¡æœ‰æœ‰æ•ˆè¯­éŸ³åˆ™è¿”å› None
        """
        import sounddevice as sd

        self._ensure_model()

        print(prompt, end="", flush=True)

        frame_samples = int(SAMPLE_RATE * FRAME_DURATION_MS / 1000)
        audio_queue: queue.Queue = queue.Queue()

        def audio_callback(indata, frames, time_info, status):
            audio_queue.put(indata.copy())

        # çŠ¶æ€æœº
        recording = False
        speech_frames = 0
        silence_start = 0.0
        all_frames = []

        with sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=DTYPE,
            blocksize=frame_samples,
            callback=audio_callback,
        ):
            start_time = time.time()

            while True:
                # è¶…æ—¶ä¿æŠ¤
                if time.time() - start_time > MAX_RECORD_SECONDS:
                    if recording:
                        break
                    else:
                        print(" (è¶…æ—¶ï¼Œæœªæ£€æµ‹åˆ°è¯­éŸ³)")
                        return None

                try:
                    frame = audio_queue.get(timeout=0.5)
                except queue.Empty:
                    continue

                rms = np.sqrt(np.mean(frame ** 2))

                if not recording:
                    # ç­‰å¾…è¯´è¯å¼€å§‹
                    if rms > SILENCE_THRESHOLD:
                        speech_frames += 1
                        if speech_frames >= SPEECH_START_FRAMES:
                            recording = True
                            print(" å½•éŸ³ä¸­...", end="", flush=True)
                            # æŠŠä¹‹å‰å‡ å¸§ä¹ŸåŠ è¿›å»ï¼ˆæ•è·å¼€å¤´ï¼‰
                            all_frames.append(frame)
                    else:
                        speech_frames = 0
                else:
                    # æ­£åœ¨å½•éŸ³
                    all_frames.append(frame)

                    if rms < SILENCE_THRESHOLD:
                        if silence_start == 0:
                            silence_start = time.time()
                        elif time.time() - silence_start > SILENCE_END_SECONDS:
                            # é™éŸ³è¶…è¿‡é˜ˆå€¼ï¼Œåœæ­¢å½•éŸ³
                            break
                    else:
                        silence_start = 0.0

        if not all_frames:
            print(" (æ— æœ‰æ•ˆéŸ³é¢‘)")
            return None

        # åˆå¹¶éŸ³é¢‘
        audio_data = np.concatenate(all_frames, axis=0).flatten()
        duration = len(audio_data) / SAMPLE_RATE
        print(f" ({duration:.1f}s)")

        if duration < 0.3:
            return None

        # è¯†åˆ«
        text = self.transcribe(audio_data)
        return text if text else None

    def is_available(self) -> bool:
        """æ£€æŸ¥éŸ³é¢‘è®¾å¤‡æ˜¯å¦å¯ç”¨"""
        try:
            import sounddevice as sd
            devices = sd.query_devices()
            # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥è®¾å¤‡
            for d in devices if isinstance(devices, list) else [devices]:
                if isinstance(d, dict) and d.get("max_input_channels", 0) > 0:
                    return True
            return False
        except Exception:
            return False
